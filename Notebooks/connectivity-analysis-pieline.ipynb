{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity Analysis Pipeline\n",
    "\n",
    "This notebook is a first shot at making a connectivity analysis pipeline using **EBRAINS** atlas services through **siibra**, and **nilearn**. \n",
    "\n",
    "The pipeline will ideally contains the following steps:\n",
    "\n",
    "- **Step 1:** <a href='#Step1'>Load fmri data from EBRAINS</a\n",
    "- **Step 2:** <a href='#Step2'>Load a parcellation from EBRAINS human brain atlas using the `siibra` client</a>\n",
    "- **Step 3:** <a href='#Step3'>Use nilearn to extract signals</a>\n",
    "- **Step 4:** <a href='#Step4'>Use nilearn to compute some connectivity from these signals</a>\n",
    "- **Step 5:** <a href='#Step5'>Use nilearn to visualize this connectivity (as a matrix, as a graph...)</a>\n",
    "- **Step 6:** <a href='#Step6'>Upload the results back to EBRAINS</a>\n",
    "- **Step 7:** Visualize them using the visualization tools of EBRAINS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load fmri data\n",
    "\n",
    "Ideally this will be loaded from **EBRAINS**. \n",
    "\n",
    "**TODOS:**\n",
    "\n",
    "- [ ] find and upload good datasets\n",
    "- [ ] find a way to fetch them easily \n",
    "\n",
    "For now, we rely on **Nilearn** for this.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> If you don't have Nilearn installed, you can get it with pip:\n",
    "\n",
    "$ pip install nilearn\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not display warnings to prettify the notebook...\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nilearn newest version (make sure it is 0.8.0 or more)\n",
    "import nilearn\n",
    "nilearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load 10 development fmri data for 10 subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_development_fmri\n",
    "\n",
    "# Ten subjects of brain development fmri data\n",
    "data = fetch_development_fmri(n_subjects=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load an atlas from EBRAINS\n",
    "\n",
    "We rely on the `siibra` library to work with EBRAINS human brain atlas and access the *Julich-Brain Probabilistic Cytoarchitectonic Maps*. We use a recent development version which we install from github:\n",
    "\n",
    "```\n",
    "pip install git+git://github.com/FZJ-INM1-BDA/siibra-python@v0.2a51#egg=siibra\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is the first time you use siibra, you will have to provide an authentication token. See [here](https://kg.ebrains.eu/develop.html) how to getn EBRAINS account and prepare it for API tokens. The, we just need to visit the token endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "webbrowser.open('https://nexus-iam.humanbrainproject.org/v0/oauth2/authorize')\n",
    "token = input(\"Enter your token here: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fetch a parcellation object via siibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+git://github.com/FZJ-INM1-BDA/siibra-python@v0.2a51#egg=siibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import siibra\n",
    "assert(siibra.__version__ >= \"0.2a51\")\n",
    "with siibra.QUIET:\n",
    "    siibra.set_ebrains_token(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a parcellation among the possible choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = siibra.atlases['human']\n",
    "parcellation = atlas.get_parcellation('julich')\n",
    "print(parcellation.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Retrieve a parcellation map in MNI152 space\n",
    "\n",
    "We load the map for this parcellation in MNI152 space. The map is an object which provides access to possibly multiple labelled 3D volumes, and keeps track of the relationship between map indices, label indices and the corresponding regions. It follows a lazy data loading scheme. In order to load image data, the `fetch()` or `fetchall()` methods are used. While the first loads image data for one particular volumetric map (with the first one as the default), the latter provides an iterator over all available maps. \n",
    "\n",
    "For the Julich-Brain maximum probability parcellation, the map provides two labelled volumes for the left and right hemisphere, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jubrain_mpm = atlas.get_map(space=\"mni152\", maptype=\"labelled\")\n",
    "# note that the above is a short form. \n",
    "# We could also use safe autocompletion by writing\n",
    "# - space=siibra.spaces.MNI152_2009C_NONL_ASYM and \n",
    "# - maptype=siibra.MapType.LABELLED \n",
    "print(f\"Julich brain provides {len(jubrain_mpm)} labelled maps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over the 3D image volumes, and display them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "for img in jubrain_mpm.fetch_iter():\n",
    "    nilearn.plotting.plot_stat_map(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Understand handling of region objects and map indices in siibra\n",
    "\n",
    "The parcellation map allows us to decode map and label indices into region objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region1 = jubrain_mpm.decode_label(mapindex=0, labelindex=10)\n",
    "print(region1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region2 = jubrain_mpm.decode_label(mapindex=1, labelindex=10)\n",
    "print(region2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the very same fashion we can access the more detailed probability maps for each region, by requesting the \"continuous\" map type. This gives us a parcellation map with hundreds of volumetric maps, each representing one brain region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jubrain_pmaps = atlas.get_map(space=\"mni152\", maptype=\"continuous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the probability map for region1 from above. Again, the parcellation map object helps us, as it can not only decode indices into regions, but also vice versa: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = jubrain_pmaps.decode_region(region2)[0]\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the region with label 10 in the second labelled parcelation map for Julich-Brain, which is \"hOc3v right\", is the 93rd map in the probability map object. It has no labelindex, since all its voxels have different values, as they represent a continuous distribution in space. \n",
    "\n",
    "Let's fetch and plot the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(jubrain_pmaps.fetch(mapindex=index.map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But in fact, fetching a single region's map can also be done much easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(jubrain_pmaps.fetch_regionmap(\"hoc3v right\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the maximum probability map, the same will give us a binary mask of that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(jubrain_mpm.fetch_regionmap(\"hoc3v right\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Use Nilearn to extract signals from parcellation and functional data\n",
    "\n",
    "In this section we use the nilearn `NiftiLabelsMasker` to extract the signals from the functional dataset and parcellation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='masker.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*copyright - Image taken from the nilearn documentation.*\n",
    "\n",
    "More information on maskers can be found in the <a href=\"https://nilearn.github.io/manipulating_images/masker_objects.html\">nilearn online documentation</a>.\n",
    "\n",
    "For masking, we use only left hemisphere parcellation map of Julich-Brain.\n",
    "\n",
    "**TODO: here we input the map with 147 different labels (plus background 0), but the masker gives us only 146 regional signals. How does the masker map labels to outputs? If it doesn't use all for some reasone, it should provide a mapping of input labels to output indices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "import numpy as np\n",
    "\n",
    "parcellation_map_niimg = jubrain_mpm.fetch(mapindex=0)\n",
    "names = {\n",
    "    index.label:region.name \n",
    "    for index, region in jubrain_mpm.regions.items()\n",
    "}\n",
    "labels = [\n",
    "    names[i] if i in names else \"\"\n",
    "    for i in range(int(max(names.keys()))+1)\n",
    "]\n",
    "\n",
    "# Use NiftiLabelsMasker to extract signals from regions\n",
    "masker = NiftiLabelsMasker(labels_img = parcellation_map_niimg, \n",
    "                           labels = labels,\n",
    "                           standardize=True) # Standardize the signals\n",
    "time_series = []\n",
    "for func, confounds in zip(data.func, data.confounds):\n",
    "    time_series.append(masker.fit_transform(func, \n",
    "                                            confounds=confounds))\n",
    "time_series = np.array(time_series)\n",
    "time_series.shape, len(names), len(np.unique(parcellation_map_niimg.get_fdata()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **146** standardized time series of length **168** per subject (**10** subjects were loaded). \n",
    "\n",
    "We can plot them if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subject_id = 0\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "for i in [0,1,2]:\n",
    "    plt.plot(time_series[subject_id, :, i], \n",
    "             label=f\"{names[i+1]:30.30}\")\n",
    "plt.legend()\n",
    "plt.xlim((0, 168))\n",
    "plt.xlabel(\"Time\", fontsize=15)\n",
    "plt.title(f\"Signals for subject {subject_id} for three regions\", fontsize=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Use Nilearn to compute a connectivity matrix\n",
    "\n",
    "Here we compute the correlation between these time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrix = correlation_measure.fit_transform(time_series)\n",
    "assert correlation_matrix.shape == (10, 146, 146)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize this matrix, we take the mean accross subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_correlation_matrix = correlation_measure.mean_\n",
    "assert mean_correlation_matrix.shape == (146, 146)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Use nilearn to visualize the connectivity\n",
    "\n",
    "We can use **Nilearn** to visualize the connectivity, either as a matrix or as a graph:\n",
    "\n",
    "### As a matrix\n",
    "\n",
    "We can plot the matrix with the region names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_correlation_matrix.shape, len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_matrix\n",
    "# Mask the main diagonal for visualization:\n",
    "np.fill_diagonal(mean_correlation_matrix, 0)\n",
    "# matrices are ordered for block-like representation\n",
    "plot_matrix(mean_correlation_matrix, \n",
    "            figure=(16, 16), \n",
    "            labels=names, \n",
    "            reorder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_connectome, find_parcellation_cut_coords\n",
    "\n",
    "# grab center coordinates for atlas labels\n",
    "coordinates = find_parcellation_cut_coords(labels_img=parcellation_map_niimg)\n",
    "# plot connectome with 95% edge strength in the connectivity\n",
    "plot_connectome(mean_correlation_matrix, \n",
    "                coordinates,\n",
    "                edge_threshold=\"95%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Upload the results back to ebrains\n",
    "\n",
    "**TODOS:**\n",
    "\n",
    "- Decide on a representation of the connectivity results\n",
    "- Find how these results could be uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siibra.features.connectivity import ConnectivityMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ConnectivityMatrix(parcellation_map_niimg, \n",
    "                       mean_correlation_matrix, \n",
    "                       names, \n",
    "                       None, None) # What are these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.parcellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
